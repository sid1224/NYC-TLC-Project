{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DtNBZFHO3M7n"
   },
   "source": [
    "# **NYC TLC Project Part 5**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ttxbfHXzB4e"
   },
   "source": [
    "Build a machine learning model to predict if a customer will not leave a tip. This can further aid in using the model in an app that will alert taxi drivers to customers who are unlikely to tip, since drivers depend on tips.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rgSbVJvomcVa"
   },
   "source": [
    "# Build a machine learning model\n",
    "\n",
    "In this project, we will use tree-based modeling techniques to predict on a binary target class.  \n",
    "<br/>   \n",
    "\n",
    "**The purpose** of this model is to find ways to generate more revenue for taxi cab drivers.  \n",
    "  \n",
    "**The goal** of this model is to predict whether or not a customer is a generous tipper.  \n",
    "<br/>  \n",
    "\n",
    "*This activity has three parts:*\n",
    "\n",
    "**Part 1:** Ethical considerations \n",
    "\n",
    "**Part 2:** Feature engineering\n",
    "\n",
    "**Part 3:** Modeling\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GUUrVKTe4cc5"
   },
   "source": [
    "Ideally, we'd have behavioral history for each customer, so we could know how much they tipped on previous taxi rides. We'd also want times, dates, and locations of both pickups and dropoffs, estimated fares, and payment method.\n",
    "\n",
    "\n",
    "The target variable would be a binary variable (1 or 0) that indicates whether or not the customer is expected to tip ≥ 20%.\n",
    "\n",
    "This is a supervised learning, classification task. We could use accuracy, precision, recall, F-score, area under the ROC curve, or a number of other metrics. However, we don't have enough information at this time to know which are most appropriate. We need to know the class balance of the target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e8Vm3QEfGELS"
   },
   "source": [
    "### **Task 1. Imports and data loading**\n",
    "\n",
    "Import packages and libraries needed to build and evaluate random forest and XGBoost classification models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "fKhnX2Puf4Bt"
   },
   "outputs": [],
   "source": [
    "# Import packages and libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, PredefinedSplit, GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, RocCurveDisplay\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier, plot_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THIS CELL TO SEE ALL COLUMNS \n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "5weTXGKqa_iG"
   },
   "outputs": [],
   "source": [
    "# Load dataset into dataframe\n",
    "df0 = pd.read_csv('2017_Yellow_Taxi_Trip_Data.csv')\n",
    "\n",
    "# Import predicted fares and mean distance and duration from previous course\n",
    "nyc_preds_means = pd.read_csv('nyc_preds_means.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the first few rows of `df0`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24870114</td>\n",
       "      <td>2</td>\n",
       "      <td>03/25/2017 8:55:43 AM</td>\n",
       "      <td>03/25/2017 9:09:47 AM</td>\n",
       "      <td>6</td>\n",
       "      <td>3.34</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>100</td>\n",
       "      <td>231</td>\n",
       "      <td>1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>16.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35634249</td>\n",
       "      <td>1</td>\n",
       "      <td>04/11/2017 2:53:28 PM</td>\n",
       "      <td>04/11/2017 3:19:58 PM</td>\n",
       "      <td>1</td>\n",
       "      <td>1.80</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>186</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>20.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>106203690</td>\n",
       "      <td>1</td>\n",
       "      <td>12/15/2017 7:26:56 AM</td>\n",
       "      <td>12/15/2017 7:34:08 AM</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>262</td>\n",
       "      <td>236</td>\n",
       "      <td>1</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>8.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38942136</td>\n",
       "      <td>2</td>\n",
       "      <td>05/07/2017 1:17:59 PM</td>\n",
       "      <td>05/07/2017 1:48:14 PM</td>\n",
       "      <td>1</td>\n",
       "      <td>3.70</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>188</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "      <td>20.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>6.39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>27.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30841670</td>\n",
       "      <td>2</td>\n",
       "      <td>04/15/2017 11:32:20 PM</td>\n",
       "      <td>04/15/2017 11:49:03 PM</td>\n",
       "      <td>1</td>\n",
       "      <td>4.37</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>4</td>\n",
       "      <td>112</td>\n",
       "      <td>2</td>\n",
       "      <td>16.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>17.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>23345809</td>\n",
       "      <td>2</td>\n",
       "      <td>03/25/2017 8:34:11 PM</td>\n",
       "      <td>03/25/2017 8:42:11 PM</td>\n",
       "      <td>6</td>\n",
       "      <td>2.30</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>161</td>\n",
       "      <td>236</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>12.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>37660487</td>\n",
       "      <td>2</td>\n",
       "      <td>05/03/2017 7:04:09 PM</td>\n",
       "      <td>05/03/2017 8:03:47 PM</td>\n",
       "      <td>1</td>\n",
       "      <td>12.83</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>79</td>\n",
       "      <td>241</td>\n",
       "      <td>1</td>\n",
       "      <td>47.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>9.86</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>59.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>69059411</td>\n",
       "      <td>2</td>\n",
       "      <td>08/15/2017 5:41:06 PM</td>\n",
       "      <td>08/15/2017 6:03:05 PM</td>\n",
       "      <td>1</td>\n",
       "      <td>2.98</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>237</td>\n",
       "      <td>114</td>\n",
       "      <td>1</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>19.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8433159</td>\n",
       "      <td>2</td>\n",
       "      <td>02/04/2017 4:17:07 PM</td>\n",
       "      <td>02/04/2017 4:29:14 PM</td>\n",
       "      <td>1</td>\n",
       "      <td>1.20</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>234</td>\n",
       "      <td>249</td>\n",
       "      <td>2</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>9.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>95294817</td>\n",
       "      <td>1</td>\n",
       "      <td>11/10/2017 3:20:29 PM</td>\n",
       "      <td>11/10/2017 3:40:55 PM</td>\n",
       "      <td>1</td>\n",
       "      <td>1.60</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>239</td>\n",
       "      <td>237</td>\n",
       "      <td>1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>16.55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  VendorID    tpep_pickup_datetime   tpep_dropoff_datetime  \\\n",
       "0    24870114         2   03/25/2017 8:55:43 AM   03/25/2017 9:09:47 AM   \n",
       "1    35634249         1   04/11/2017 2:53:28 PM   04/11/2017 3:19:58 PM   \n",
       "2   106203690         1   12/15/2017 7:26:56 AM   12/15/2017 7:34:08 AM   \n",
       "3    38942136         2   05/07/2017 1:17:59 PM   05/07/2017 1:48:14 PM   \n",
       "4    30841670         2  04/15/2017 11:32:20 PM  04/15/2017 11:49:03 PM   \n",
       "5    23345809         2   03/25/2017 8:34:11 PM   03/25/2017 8:42:11 PM   \n",
       "6    37660487         2   05/03/2017 7:04:09 PM   05/03/2017 8:03:47 PM   \n",
       "7    69059411         2   08/15/2017 5:41:06 PM   08/15/2017 6:03:05 PM   \n",
       "8     8433159         2   02/04/2017 4:17:07 PM   02/04/2017 4:29:14 PM   \n",
       "9    95294817         1   11/10/2017 3:20:29 PM   11/10/2017 3:40:55 PM   \n",
       "\n",
       "   passenger_count  trip_distance  RatecodeID store_and_fwd_flag  \\\n",
       "0                6           3.34           1                  N   \n",
       "1                1           1.80           1                  N   \n",
       "2                1           1.00           1                  N   \n",
       "3                1           3.70           1                  N   \n",
       "4                1           4.37           1                  N   \n",
       "5                6           2.30           1                  N   \n",
       "6                1          12.83           1                  N   \n",
       "7                1           2.98           1                  N   \n",
       "8                1           1.20           1                  N   \n",
       "9                1           1.60           1                  N   \n",
       "\n",
       "   PULocationID  DOLocationID  payment_type  fare_amount  extra  mta_tax  \\\n",
       "0           100           231             1         13.0    0.0      0.5   \n",
       "1           186            43             1         16.0    0.0      0.5   \n",
       "2           262           236             1          6.5    0.0      0.5   \n",
       "3           188            97             1         20.5    0.0      0.5   \n",
       "4             4           112             2         16.5    0.5      0.5   \n",
       "5           161           236             1          9.0    0.5      0.5   \n",
       "6            79           241             1         47.5    1.0      0.5   \n",
       "7           237           114             1         16.0    1.0      0.5   \n",
       "8           234           249             2          9.0    0.0      0.5   \n",
       "9           239           237             1         13.0    0.0      0.5   \n",
       "\n",
       "   tip_amount  tolls_amount  improvement_surcharge  total_amount  \n",
       "0        2.76           0.0                    0.3         16.56  \n",
       "1        4.00           0.0                    0.3         20.80  \n",
       "2        1.45           0.0                    0.3          8.75  \n",
       "3        6.39           0.0                    0.3         27.69  \n",
       "4        0.00           0.0                    0.3         17.80  \n",
       "5        2.06           0.0                    0.3         12.36  \n",
       "6        9.86           0.0                    0.3         59.16  \n",
       "7        1.78           0.0                    0.3         19.58  \n",
       "8        0.00           0.0                    0.3          9.80  \n",
       "9        2.75           0.0                    0.3         16.55  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the first few rows of df0\n",
    "\n",
    "df0.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the first few rows of `nyc_preds_means`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_duration</th>\n",
       "      <th>mean_distance</th>\n",
       "      <th>predicted_fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.847222</td>\n",
       "      <td>3.521667</td>\n",
       "      <td>16.434245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24.470370</td>\n",
       "      <td>3.108889</td>\n",
       "      <td>16.052218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.250000</td>\n",
       "      <td>0.881429</td>\n",
       "      <td>7.053706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30.250000</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>18.731650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.616667</td>\n",
       "      <td>4.435000</td>\n",
       "      <td>15.845642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11.855376</td>\n",
       "      <td>2.052258</td>\n",
       "      <td>10.441351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>59.633333</td>\n",
       "      <td>12.830000</td>\n",
       "      <td>45.374542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>26.437500</td>\n",
       "      <td>4.022500</td>\n",
       "      <td>18.555128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7.873457</td>\n",
       "      <td>1.019259</td>\n",
       "      <td>7.151511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.541111</td>\n",
       "      <td>1.580000</td>\n",
       "      <td>9.122755</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_duration  mean_distance  predicted_fare\n",
       "0      22.847222       3.521667       16.434245\n",
       "1      24.470370       3.108889       16.052218\n",
       "2       7.250000       0.881429        7.053706\n",
       "3      30.250000       3.700000       18.731650\n",
       "4      14.616667       4.435000       15.845642\n",
       "5      11.855376       2.052258       10.441351\n",
       "6      59.633333      12.830000       45.374542\n",
       "7      26.437500       4.022500       18.555128\n",
       "8       7.873457       1.019259        7.151511\n",
       "9      10.541111       1.580000        9.122755"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the first few rows of `nyc_preds_means`\n",
    "\n",
    "nyc_preds_means.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Join the two dataframes\n",
    "\n",
    "Join the two dataframes using any method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>mean_duration</th>\n",
       "      <th>mean_distance</th>\n",
       "      <th>predicted_fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24870114</td>\n",
       "      <td>2</td>\n",
       "      <td>03/25/2017 8:55:43 AM</td>\n",
       "      <td>03/25/2017 9:09:47 AM</td>\n",
       "      <td>6</td>\n",
       "      <td>3.34</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>100</td>\n",
       "      <td>231</td>\n",
       "      <td>1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>16.56</td>\n",
       "      <td>22.847222</td>\n",
       "      <td>3.521667</td>\n",
       "      <td>16.434245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35634249</td>\n",
       "      <td>1</td>\n",
       "      <td>04/11/2017 2:53:28 PM</td>\n",
       "      <td>04/11/2017 3:19:58 PM</td>\n",
       "      <td>1</td>\n",
       "      <td>1.80</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>186</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>20.80</td>\n",
       "      <td>24.470370</td>\n",
       "      <td>3.108889</td>\n",
       "      <td>16.052218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>106203690</td>\n",
       "      <td>1</td>\n",
       "      <td>12/15/2017 7:26:56 AM</td>\n",
       "      <td>12/15/2017 7:34:08 AM</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>262</td>\n",
       "      <td>236</td>\n",
       "      <td>1</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>8.75</td>\n",
       "      <td>7.250000</td>\n",
       "      <td>0.881429</td>\n",
       "      <td>7.053706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38942136</td>\n",
       "      <td>2</td>\n",
       "      <td>05/07/2017 1:17:59 PM</td>\n",
       "      <td>05/07/2017 1:48:14 PM</td>\n",
       "      <td>1</td>\n",
       "      <td>3.70</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>188</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "      <td>20.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>6.39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>27.69</td>\n",
       "      <td>30.250000</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>18.731650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30841670</td>\n",
       "      <td>2</td>\n",
       "      <td>04/15/2017 11:32:20 PM</td>\n",
       "      <td>04/15/2017 11:49:03 PM</td>\n",
       "      <td>1</td>\n",
       "      <td>4.37</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>4</td>\n",
       "      <td>112</td>\n",
       "      <td>2</td>\n",
       "      <td>16.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>17.80</td>\n",
       "      <td>14.616667</td>\n",
       "      <td>4.435000</td>\n",
       "      <td>15.845642</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  VendorID    tpep_pickup_datetime   tpep_dropoff_datetime  \\\n",
       "0    24870114         2   03/25/2017 8:55:43 AM   03/25/2017 9:09:47 AM   \n",
       "1    35634249         1   04/11/2017 2:53:28 PM   04/11/2017 3:19:58 PM   \n",
       "2   106203690         1   12/15/2017 7:26:56 AM   12/15/2017 7:34:08 AM   \n",
       "3    38942136         2   05/07/2017 1:17:59 PM   05/07/2017 1:48:14 PM   \n",
       "4    30841670         2  04/15/2017 11:32:20 PM  04/15/2017 11:49:03 PM   \n",
       "\n",
       "   passenger_count  trip_distance  RatecodeID store_and_fwd_flag  \\\n",
       "0                6           3.34           1                  N   \n",
       "1                1           1.80           1                  N   \n",
       "2                1           1.00           1                  N   \n",
       "3                1           3.70           1                  N   \n",
       "4                1           4.37           1                  N   \n",
       "\n",
       "   PULocationID  DOLocationID  payment_type  fare_amount  extra  mta_tax  \\\n",
       "0           100           231             1         13.0    0.0      0.5   \n",
       "1           186            43             1         16.0    0.0      0.5   \n",
       "2           262           236             1          6.5    0.0      0.5   \n",
       "3           188            97             1         20.5    0.0      0.5   \n",
       "4             4           112             2         16.5    0.5      0.5   \n",
       "\n",
       "   tip_amount  tolls_amount  improvement_surcharge  total_amount  \\\n",
       "0        2.76           0.0                    0.3         16.56   \n",
       "1        4.00           0.0                    0.3         20.80   \n",
       "2        1.45           0.0                    0.3          8.75   \n",
       "3        6.39           0.0                    0.3         27.69   \n",
       "4        0.00           0.0                    0.3         17.80   \n",
       "\n",
       "   mean_duration  mean_distance  predicted_fare  \n",
       "0      22.847222       3.521667       16.434245  \n",
       "1      24.470370       3.108889       16.052218  \n",
       "2       7.250000       0.881429        7.053706  \n",
       "3      30.250000       3.700000       18.731650  \n",
       "4      14.616667       4.435000       15.845642  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge datasets\n",
    "df0 = df0.merge(nyc_preds_means, left_index=True, right_index=True)\n",
    "df0.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5VZowX9rhU1o"
   },
   "source": [
    "### **Task 2. Feature engineering**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "mBOSW8IDbO_d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22699 entries, 0 to 22698\n",
      "Data columns (total 21 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   Unnamed: 0             22699 non-null  int64  \n",
      " 1   VendorID               22699 non-null  int64  \n",
      " 2   tpep_pickup_datetime   22699 non-null  object \n",
      " 3   tpep_dropoff_datetime  22699 non-null  object \n",
      " 4   passenger_count        22699 non-null  int64  \n",
      " 5   trip_distance          22699 non-null  float64\n",
      " 6   RatecodeID             22699 non-null  int64  \n",
      " 7   store_and_fwd_flag     22699 non-null  object \n",
      " 8   PULocationID           22699 non-null  int64  \n",
      " 9   DOLocationID           22699 non-null  int64  \n",
      " 10  payment_type           22699 non-null  int64  \n",
      " 11  fare_amount            22699 non-null  float64\n",
      " 12  extra                  22699 non-null  float64\n",
      " 13  mta_tax                22699 non-null  float64\n",
      " 14  tip_amount             22699 non-null  float64\n",
      " 15  tolls_amount           22699 non-null  float64\n",
      " 16  improvement_surcharge  22699 non-null  float64\n",
      " 17  total_amount           22699 non-null  float64\n",
      " 18  mean_duration          22699 non-null  float64\n",
      " 19  mean_distance          22699 non-null  float64\n",
      " 20  predicted_fare         22699 non-null  float64\n",
      "dtypes: float64(11), int64(7), object(3)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df0.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0D2RvXk0kwsx"
   },
   "source": [
    "We know from our EDA that customers who pay cash generally have a tip amount of $0. To meet the modeling objective, we'll need to sample the data to select only the customers who pay with credit card. \n",
    "\n",
    "Copy `df0` and assign the result to a variable called `df1`. Then, use a Boolean mask to filter `df1` so it contains only customers who paid with credit card."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "_pmNd78plQYr"
   },
   "outputs": [],
   "source": [
    "# Subset the data to isolate only customers who paid by credit card\n",
    "df1 = df0[df0['payment_type']==1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EcYudtSYyMcZ"
   },
   "source": [
    "##### **Target**\n",
    "\n",
    "Notice that there isn't a column that indicates tip percent, which is what we need to create the target variable. We'll have to engineer it. \n",
    "\n",
    "Add a `tip_percent` column to the dataframe by performing the following calculation:  \n",
    "<br/>  \n",
    "\n",
    "\n",
    "$$tip\\ percent = \\frac{tip\\ amount}{total\\ amount - tip\\ amount}$$  \n",
    "\n",
    "Round the result to three places beyond the decimal. **This is an important step.** It affects how many customers are labeled as generous tippers. In fact, without performing this step, approximately 1,800 people who do tip ≥ 20% would be labeled as not generous. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "guanzJd8zBla"
   },
   "outputs": [],
   "source": [
    "# Create tip % col\n",
    "\n",
    "df1['tip_percent'] = round(df1['tip_amount']/(df1['total_amount']-df1['tip_amount']),3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bqb-SWfs-8Xn"
   },
   "source": [
    "Now create another column called `generous`. This will be the target variable. The column should be a binary indicator of whether or not a customer tipped ≥ 20% (0=no, 1=yes).\n",
    "\n",
    "1. Begin by making the `generous` column a copy of the `tip_percent` column.\n",
    "2. Reassign the column by converting it to Boolean (True/False).\n",
    "3. Reassign the column by converting Boolean to binary (1/0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "nqDSe0DSGwhB"
   },
   "outputs": [],
   "source": [
    "# Create 'generous' col (target)\n",
    "df1['generous'] = df1['tip_percent']\n",
    "df1['generous'] = (df1['generous']>=0.2)\n",
    "df1['generous'] = df1['generous'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create day column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H27zUVIlkaxA"
   },
   "source": [
    "\n",
    "Convert the `tpep_pickup_datetime` and `tpep_dropoff_datetime` columns to datetime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "OIycxWBMkafJ"
   },
   "outputs": [],
   "source": [
    "# Convert pickup and dropoff cols to datetime\n",
    "\n",
    "df1['tpep_pickup_datetime'] = pd.to_datetime(df1['tpep_pickup_datetime'], format='%m/%d/%Y %I:%M:%S %p')\n",
    "df1['tpep_dropoff_datetime'] = pd.to_datetime(df1['tpep_dropoff_datetime'], format='%m/%d/%Y %I:%M:%S %p')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zpcM4FvNyPFY"
   },
   "source": [
    "Create a `day` column that contains only the day of the week when each passenger was picked up. Then, convert the values to lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "abUvtMaYyWpD"
   },
   "outputs": [],
   "source": [
    "# Create a 'day' col\n",
    "\n",
    "df1['day'] = df1['tpep_pickup_datetime'].dt.day_name().str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create time of day columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HwslVt8Hpu7x"
   },
   "source": [
    "Next, engineer four new columns that represent time of day bins. Each column should contain binary values (0=no, 1=yes) that indicate whether a trip began (picked up) during the following times:\n",
    "\n",
    "`am_rush` = [06:00&ndash;10:00)  \n",
    "`daytime` = [10:00&ndash;16:00)  \n",
    "`pm_rush` = [16:00&ndash;20:00)  \n",
    "`nighttime` = [20:00&ndash;06:00)  \n",
    "\n",
    "To do this, first create the four columns. For now, each new column should be identical and contain the same information: the hour (only) from the `tpep_pickup_datetime` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "x8LFySUyprau"
   },
   "outputs": [],
   "source": [
    "# Create 'am_rush' col\n",
    "\n",
    "df1['am_rush'] = df1['tpep_pickup_datetime'].dt.hour\n",
    "\n",
    "# Create 'daytime' col\n",
    "\n",
    "df1['daytime'] = df1['tpep_pickup_datetime'].dt.hour\n",
    "\n",
    "# Create 'pm_rush' col\n",
    "\n",
    "df1['pm_rush'] = df1['tpep_pickup_datetime'].dt.hour\n",
    "\n",
    "# Create 'nighttime' col\n",
    "\n",
    "df1['nighttime'] = df1['tpep_pickup_datetime'].dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "oAE4vRz0wGtN"
   },
   "outputs": [],
   "source": [
    "# Define 'am_rush()' conversion function [06:00–10:00)\n",
    "\n",
    "def am_rush(hour):\n",
    "    if 6 <= hour['am_rush'] < 10:\n",
    "        val = 1\n",
    "    else:\n",
    "        val = 0\n",
    "    return val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hHY1-6cIxfA6"
   },
   "source": [
    "Now, apply the `am_rush()` function to the `am_rush` series to perform the conversion. Print the first five values of the column to make sure it did what you expected it to do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "sWFojyk9xdDY"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    0\n",
       "2    1\n",
       "3    0\n",
       "5    0\n",
       "Name: am_rush, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply 'am_rush' function to the 'am_rush' series\n",
    "\n",
    "df1['am_rush'] = df1.apply(am_rush, axis=1)\n",
    "df1['am_rush'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mSY6SsdK0lpn"
   },
   "source": [
    "Write functions to convert the three remaining columns and apply them to their respective series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "UADnzaIjzwLG"
   },
   "outputs": [],
   "source": [
    "# Define 'daytime()' conversion function [10:00–16:00)\n",
    "\n",
    "def daytime(hour):\n",
    "    if 10 <= hour['daytime'] < 16:\n",
    "        val = 1\n",
    "    else:\n",
    "        val = 0\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "ReHpKxoC1Qsx"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "2    0\n",
       "3    1\n",
       "5    0\n",
       "Name: daytime, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply 'daytime()' function to the 'daytime' series\n",
    "\n",
    "df1['daytime'] = df1.apply(daytime, axis=1)\n",
    "df1['daytime'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "rP-ZBOHT1WQY"
   },
   "outputs": [],
   "source": [
    "# Define 'pm_rush()' conversion function [16:00–20:00)\n",
    "\n",
    "def pm_rush(hour):\n",
    "    if 16 <= hour['pm_rush'] < 20:\n",
    "        val = 1\n",
    "    else:\n",
    "        val = 0\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "h0zWPBqr1mX4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "5    0\n",
       "Name: pm_rush, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply 'pm_rush()' function to the 'pm_rush' series\n",
    "\n",
    "df1['pm_rush'] = df1.apply(pm_rush, axis=1)\n",
    "df1['pm_rush'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "u5O0LPLz2CSa"
   },
   "outputs": [],
   "source": [
    "# Define 'nighttime()' conversion function [20:00–06:00)\n",
    "\n",
    "def nighttime(hour):\n",
    "    if 20 <= hour['nighttime'] < 24:\n",
    "        val = 1\n",
    "    elif 0 <= hour['nighttime'] < 6:\n",
    "        val = 1\n",
    "    else:\n",
    "        val = 0\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "kLGmBXkT2RTi"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "5    1\n",
       "Name: nighttime, dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply 'nighttime' function to the 'nighttime' series\n",
    "\n",
    "df1['nighttime'] = df1.apply(nighttime, axis=1)\n",
    "df1['nighttime'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create `month` column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VrUmDy8U28bs"
   },
   "source": [
    "Now, create a `month` column that contains only the abbreviated name of the month when each passenger was picked up, then convert the result to lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 'month' col\n",
    "\n",
    "df1['month'] = df1['tpep_pickup_datetime'].dt.strftime('%b').str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qWbNVbngihE6"
   },
   "source": [
    "Examine the first five rows of your dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "jWxemeyl4vwQ"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>mean_duration</th>\n",
       "      <th>mean_distance</th>\n",
       "      <th>predicted_fare</th>\n",
       "      <th>tip_percent</th>\n",
       "      <th>generous</th>\n",
       "      <th>day</th>\n",
       "      <th>am_rush</th>\n",
       "      <th>daytime</th>\n",
       "      <th>pm_rush</th>\n",
       "      <th>nighttime</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24870114</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-03-25 08:55:43</td>\n",
       "      <td>2017-03-25 09:09:47</td>\n",
       "      <td>6</td>\n",
       "      <td>3.34</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>100</td>\n",
       "      <td>231</td>\n",
       "      <td>1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>16.56</td>\n",
       "      <td>22.847222</td>\n",
       "      <td>3.521667</td>\n",
       "      <td>16.434245</td>\n",
       "      <td>0.200</td>\n",
       "      <td>1</td>\n",
       "      <td>saturday</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>mar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35634249</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-04-11 14:53:28</td>\n",
       "      <td>2017-04-11 15:19:58</td>\n",
       "      <td>1</td>\n",
       "      <td>1.80</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>186</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>20.80</td>\n",
       "      <td>24.470370</td>\n",
       "      <td>3.108889</td>\n",
       "      <td>16.052218</td>\n",
       "      <td>0.238</td>\n",
       "      <td>1</td>\n",
       "      <td>tuesday</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>apr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>106203690</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-12-15 07:26:56</td>\n",
       "      <td>2017-12-15 07:34:08</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>262</td>\n",
       "      <td>236</td>\n",
       "      <td>1</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>8.75</td>\n",
       "      <td>7.250000</td>\n",
       "      <td>0.881429</td>\n",
       "      <td>7.053706</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0</td>\n",
       "      <td>friday</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38942136</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-05-07 13:17:59</td>\n",
       "      <td>2017-05-07 13:48:14</td>\n",
       "      <td>1</td>\n",
       "      <td>3.70</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>188</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "      <td>20.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>6.39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>27.69</td>\n",
       "      <td>30.250000</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>18.731650</td>\n",
       "      <td>0.300</td>\n",
       "      <td>1</td>\n",
       "      <td>sunday</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>may</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>23345809</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-03-25 20:34:11</td>\n",
       "      <td>2017-03-25 20:42:11</td>\n",
       "      <td>6</td>\n",
       "      <td>2.30</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>161</td>\n",
       "      <td>236</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>12.36</td>\n",
       "      <td>11.855376</td>\n",
       "      <td>2.052258</td>\n",
       "      <td>10.441351</td>\n",
       "      <td>0.200</td>\n",
       "      <td>1</td>\n",
       "      <td>saturday</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>mar</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  VendorID tpep_pickup_datetime tpep_dropoff_datetime  \\\n",
       "0    24870114         2  2017-03-25 08:55:43   2017-03-25 09:09:47   \n",
       "1    35634249         1  2017-04-11 14:53:28   2017-04-11 15:19:58   \n",
       "2   106203690         1  2017-12-15 07:26:56   2017-12-15 07:34:08   \n",
       "3    38942136         2  2017-05-07 13:17:59   2017-05-07 13:48:14   \n",
       "5    23345809         2  2017-03-25 20:34:11   2017-03-25 20:42:11   \n",
       "\n",
       "   passenger_count  trip_distance  RatecodeID store_and_fwd_flag  \\\n",
       "0                6           3.34           1                  N   \n",
       "1                1           1.80           1                  N   \n",
       "2                1           1.00           1                  N   \n",
       "3                1           3.70           1                  N   \n",
       "5                6           2.30           1                  N   \n",
       "\n",
       "   PULocationID  DOLocationID  payment_type  fare_amount  extra  mta_tax  \\\n",
       "0           100           231             1         13.0    0.0      0.5   \n",
       "1           186            43             1         16.0    0.0      0.5   \n",
       "2           262           236             1          6.5    0.0      0.5   \n",
       "3           188            97             1         20.5    0.0      0.5   \n",
       "5           161           236             1          9.0    0.5      0.5   \n",
       "\n",
       "   tip_amount  tolls_amount  improvement_surcharge  total_amount  \\\n",
       "0        2.76           0.0                    0.3         16.56   \n",
       "1        4.00           0.0                    0.3         20.80   \n",
       "2        1.45           0.0                    0.3          8.75   \n",
       "3        6.39           0.0                    0.3         27.69   \n",
       "5        2.06           0.0                    0.3         12.36   \n",
       "\n",
       "   mean_duration  mean_distance  predicted_fare  tip_percent  generous  \\\n",
       "0      22.847222       3.521667       16.434245        0.200         1   \n",
       "1      24.470370       3.108889       16.052218        0.238         1   \n",
       "2       7.250000       0.881429        7.053706        0.199         0   \n",
       "3      30.250000       3.700000       18.731650        0.300         1   \n",
       "5      11.855376       2.052258       10.441351        0.200         1   \n",
       "\n",
       "        day  am_rush  daytime  pm_rush  nighttime month  \n",
       "0  saturday        1        0        0          0   mar  \n",
       "1   tuesday        0        1        0          0   apr  \n",
       "2    friday        1        0        0          0   dec  \n",
       "3    sunday        0        1        0          0   may  \n",
       "5  saturday        0        0        0          1   mar  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#==> ENTER YOUR CODE HERE\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop columns\n",
    "\n",
    "Drop redundant and irrelevant columns as well as those that would not be available when the model is deployed. This includes information like payment type, trip distance, tip amount, tip percentage, total amount, toll amount, etc. The target variable (`generous`) must remain in the data because it will get isolated as the `y` data for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 15265 entries, 0 to 22698\n",
      "Data columns (total 15 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   VendorID         15265 non-null  int64  \n",
      " 1   passenger_count  15265 non-null  int64  \n",
      " 2   RatecodeID       15265 non-null  int64  \n",
      " 3   PULocationID     15265 non-null  int64  \n",
      " 4   DOLocationID     15265 non-null  int64  \n",
      " 5   mean_duration    15265 non-null  float64\n",
      " 6   mean_distance    15265 non-null  float64\n",
      " 7   predicted_fare   15265 non-null  float64\n",
      " 8   generous         15265 non-null  int64  \n",
      " 9   day              15265 non-null  object \n",
      " 10  am_rush          15265 non-null  int64  \n",
      " 11  daytime          15265 non-null  int64  \n",
      " 12  pm_rush          15265 non-null  int64  \n",
      " 13  nighttime        15265 non-null  int64  \n",
      " 14  month            15265 non-null  object \n",
      "dtypes: float64(3), int64(10), object(2)\n",
      "memory usage: 1.9+ MB\n"
     ]
    }
   ],
   "source": [
    "# Drop columns\n",
    "\n",
    "drop_cols = ['Unnamed: 0', 'tpep_pickup_datetime', 'tpep_dropoff_datetime',\n",
    "             'payment_type', 'trip_distance', 'store_and_fwd_flag', 'payment_type',\n",
    "             'fare_amount', 'extra', 'mta_tax', 'tip_amount', 'tolls_amount',\n",
    "             'improvement_surcharge', 'total_amount', 'tip_percent']\n",
    "\n",
    "df1 = df1.drop(drop_cols, axis=1)\n",
    "df1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variable encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BVs01W-Iitu7"
   },
   "source": [
    "Many of the columns are categorical and will need to be dummied (converted to binary). Some of these columns are numeric, but they actually encode categorical information, such as `RatecodeID` and the pickup and dropoff locations. To make these columns recognizable to the `get_dummies()` function as categorical variables, we'll first need to convert them to `type(str)`. \n",
    "\n",
    "1. Define a variable called `cols_to_str`, which is a list of the numeric columns that contain categorical information and must be converted to string: `RatecodeID`, `PULocationID`, `DOLocationID`.\n",
    "2. Write a for loop that converts each column in `cols_to_str` to string.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "FbB4AfATHqjC"
   },
   "outputs": [],
   "source": [
    "# 1. Define list of cols to convert to string\n",
    "\n",
    "cols_to_str = ['RatecodeID', 'PULocationID', 'DOLocationID', 'VendorID']\n",
    "\n",
    "# 2. Convert each column to string\n",
    "\n",
    "for col in cols_to_str:\n",
    "    df1[col] = df1[col].astype('str')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_5Ubw8O1pKRO"
   },
   "source": [
    "Now convert all the categorical columns to binary.\n",
    "\n",
    "1. Call `get_dummies()` on the dataframe and assign the results back to a new dataframe called `df2`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "H94yLzUMHqgB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 15265 entries, 0 to 22698\n",
      "Columns: 347 entries, passenger_count to month_sep\n",
      "dtypes: float64(3), int64(6), uint8(338)\n",
      "memory usage: 6.1 MB\n"
     ]
    }
   ],
   "source": [
    "# Convert categoricals to binary\n",
    "\n",
    "df2 = pd.get_dummies(df1, drop_first=True)\n",
    "df2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nZfNE37b-LlJ"
   },
   "source": [
    "##### Evaluation metric\n",
    "\n",
    "Before modeling, we must decide on an evaluation metric. \n",
    "\n",
    "1. Examine the class balance of our target variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "4mRefXCF-K_c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.526368\n",
       "0    0.473632\n",
       "Name: generous, dtype: float64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get class balance of 'generous' col\n",
    "\n",
    "df2['generous'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TjgkLrOf_OrE"
   },
   "source": [
    "A little over half of the customers in this dataset were \"generous\" (tipped ≥ 20%). The dataset is very nearly balanced.\n",
    "\n",
    "To determine a metric, consider the cost of both kinds of model error:\n",
    "* False positives (the model predicts a tip ≥ 20%, but the customer does not give one)\n",
    "* False negatives (the model predicts a tip < 20%, but the customer gives more)\n",
    "\n",
    "False positives are worse for cab drivers, because they would pick up a customer expecting a good tip and then not receive one, frustrating the driver.\n",
    "\n",
    "False negatives are worse for customers, because a cab driver would likely pick up a different customer who was predicted to tip more&mdash;even when the original customer would have tipped generously.\n",
    "\n",
    "**The stakes are relatively even. We want to help taxi drivers make more money, but we don't want this to anger customers. Our metric should weigh both precision and recall equally. So we use F1 score. **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G5jzGjOS8iiv"
   },
   "source": [
    "### **Task 3. Modeling**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nx41bVxX89Fe"
   },
   "source": [
    "##### **Split the data**\n",
    "\n",
    "The only remaining step is to split the data into features/target variable and training/testing data. \n",
    "\n",
    "1. Define a variable `y` that isolates the target variable (`generous`).\n",
    "2. Define a variable `X` that isolates the features.\n",
    "3. Split the data into training and testing sets. Put 20% of the samples into the test set, stratify the data, and set the random state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "qLbapbSWDUL-"
   },
   "outputs": [],
   "source": [
    "# Isolate target variable (y)\n",
    "\n",
    "y = df2[\"generous\"]\n",
    "\n",
    "# Isolate the features (X)\n",
    "\n",
    "x = df2.drop('generous', axis=1)\n",
    "\n",
    "# Split into train and test sets\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, stratify=y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vynZs5het1b_"
   },
   "source": [
    "##### **Random forest**\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Instantiate the random forest classifier\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# 2. Create a dictionary of hyperparameters to tune \n",
    "\n",
    "cv_params = {\n",
    "    'max_depth': [5, 10, 15],\n",
    "    'max_features': ['sqrt'],\n",
    "    'max_samples': [0.8],\n",
    "    'min_samples_leaf': [1, 3],\n",
    "    'min_samples_split': [2, 3, 5],\n",
    "    'n_estimators': [200, 300]\n",
    "}\n",
    "\n",
    "# 3. Define a set of scoring metrics to capture\n",
    "\n",
    "scoring = {'accuracy', 'precision', 'recall', 'f1'}\n",
    "\n",
    "# 4. Instantiate the GridSearchCV object\n",
    "\n",
    "rf1 = GridSearchCV(rf, cv_params, scoring=scoring, cv=5, refit='f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "OXuBiTGi5ZHn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 26s, sys: 666 ms, total: 6min 27s\n",
      "Wall time: 6min 27s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                              class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              max_samples=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators=100, n_jobs=None,\n",
       "                                              oob_score=False, random_state=42,\n",
       "                                              verbose=0, warm_start=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'max_depth': [5, 10, 15], 'max_features': ['sqrt'],\n",
       "                         'max_samples': [0.8], 'min_samples_leaf': [1, 3],\n",
       "                         'min_samples_split': [2, 3, 5],\n",
       "                         'n_estimators': [200, 300]},\n",
       "             pre_dispatch='2*n_jobs', refit='f1', return_train_score=False,\n",
       "             scoring={'precision', 'recall', 'f1', 'accuracy'}, verbose=0)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "rf1.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ChZsXw2sksDF"
   },
   "source": [
    "If needed, use `pickle` to save the models and read them back in. This can be particularly helpful when performing a search over many possible hyperparameter values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "YtAgrH0zy4CE"
   },
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "# Define a path to the folder where you want to save the model\n",
    "path = 'C:/Users/disis/Downloads'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_pickle(path, model_object, save_name:str):\n",
    "    '''\n",
    "    save_name is a string.\n",
    "    '''\n",
    "    with open(path + save_name + '.pickle', 'wb') as to_write:\n",
    "        pickle.dump(model_object, to_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pickle(path, saved_model_name:str):\n",
    "    '''\n",
    "    saved_model_name is a string.\n",
    "    '''\n",
    "    with open(path + saved_model_name + '.pickle', 'rb') as to_read:\n",
    "        model = pickle.load(to_read)\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QIaRiZW4hf-6"
   },
   "source": [
    "Examine the best average score across all the validation folds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "29kGUegqhviL"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7498766982595237"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine best score\n",
    "\n",
    "rf1.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "heGb51fHh3E5"
   },
   "source": [
    "Examine the best combination of hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "FjgXbO7Kh8is"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 5,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_samples': 0.8,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 5,\n",
       " 'n_estimators': 200}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf1.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qZZnem5yiAau"
   },
   "source": [
    "Use the `make_results()` function to output all of the scores of the model. Note that it accepts three arguments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "u-UodWEOedxz"
   },
   "outputs": [],
   "source": [
    "def make_results(model_name:str, model_object, metric:str):\n",
    "    '''\n",
    "    Arguments:\n",
    "    model_name (string): what you want the model to be called in the output table\n",
    "    model_object: a fit GridSearchCV object\n",
    "    metric (string): precision, recall, f1, or accuracy\n",
    "\n",
    "    Returns a pandas df with the F1, recall, precision, and accuracy scores\n",
    "    for the model with the best mean 'metric' score across all validation folds.\n",
    "    '''\n",
    "\n",
    "    # Create dictionary that maps input metric to actual metric name in GridSearchCV\n",
    "    metric_dict = {'precision': 'mean_test_precision',\n",
    "                 'recall': 'mean_test_recall',\n",
    "                 'f1': 'mean_test_f1',\n",
    "                 'accuracy': 'mean_test_accuracy',\n",
    "                 }\n",
    "\n",
    "    # Get all the results from the CV and put them in a df\n",
    "    cv_results = pd.DataFrame(model_object.cv_results_)\n",
    "\n",
    "    # Isolate the row of the df with the max(metric) score\n",
    "    best_estimator_results = cv_results.iloc[cv_results[metric_dict[metric]].idxmax(), :]\n",
    "\n",
    "    # Extract Accuracy, precision, recall, and f1 score from that row\n",
    "    f1 = best_estimator_results.mean_test_f1\n",
    "    recall = best_estimator_results.mean_test_recall\n",
    "    precision = best_estimator_results.mean_test_precision\n",
    "    accuracy = best_estimator_results.mean_test_accuracy\n",
    "\n",
    "    # Create table of results\n",
    "    table = pd.DataFrame({'model': [model_name],\n",
    "                        'precision': [precision],\n",
    "                        'recall': [recall],\n",
    "                        'F1': [f1],\n",
    "                        'accuracy': [accuracy],\n",
    "                        },\n",
    "                       )\n",
    "\n",
    "    return table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cI84Xo37ZLy0"
   },
   "source": [
    "Call `make_results()` on the GridSearch object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "qAYb2QigiT_h"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RF CV</td>\n",
       "      <td>0.691642</td>\n",
       "      <td>0.818917</td>\n",
       "      <td>0.749877</td>\n",
       "      <td>0.712413</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model  precision    recall        F1  accuracy\n",
       "0  RF CV   0.691642  0.818917  0.749877  0.712413"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = make_results('RF CV', rf1, 'f1')\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SB-yhW9uu7dO"
   },
   "source": [
    "Our results should produce an acceptable model across the board. Typically scores of 0.65 or better are considered acceptable, but this is always dependent on our use case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the model to predict on the test data. Assign the results to a variable called `rf_preds`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get scores on test data\n",
    "\n",
    "rf_preds = rf1.best_estimator_.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the below `get_test_scores()` function you will use to output the scores of the model on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_scores(model_name:str, preds, y_test_data):\n",
    "    '''\n",
    "    Generate a table of test scores.\n",
    "\n",
    "    In:\n",
    "    model_name (string): Your choice: how the model will be named in the output table\n",
    "    preds: numpy array of test predictions\n",
    "    y_test_data: numpy array of y_test data\n",
    "\n",
    "    Out:\n",
    "    table: a pandas df of precision, recall, f1, and accuracy scores for your model\n",
    "    '''\n",
    "    accuracy = accuracy_score(y_test_data, preds)\n",
    "    precision = precision_score(y_test_data, preds)\n",
    "    recall = recall_score(y_test_data, preds)\n",
    "    f1 = f1_score(y_test_data, preds)\n",
    "\n",
    "    table = pd.DataFrame({'model': [model_name],\n",
    "                        'precision': [precision],\n",
    "                        'recall': [recall],\n",
    "                        'F1': [f1],\n",
    "                        'accuracy': [accuracy]\n",
    "                        })\n",
    "\n",
    "    return table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FDRAL7zQx21J"
   },
   "source": [
    "1. Use the `get_test_scores()` function to generate the scores on the test data. Assign the results to `rf_test_scores`.\n",
    "2. Call `rf_test_scores` to output the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### RF test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "id": "Iil1LjabiT5x"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RF CV</td>\n",
       "      <td>0.691642</td>\n",
       "      <td>0.818917</td>\n",
       "      <td>0.749877</td>\n",
       "      <td>0.712413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RF test</td>\n",
       "      <td>0.679876</td>\n",
       "      <td>0.822029</td>\n",
       "      <td>0.744225</td>\n",
       "      <td>0.702588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     model  precision    recall        F1  accuracy\n",
       "0    RF CV   0.691642  0.818917  0.749877  0.712413\n",
       "0  RF test   0.679876  0.822029  0.744225  0.702588"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # Get scores on test data\n",
    "rf_test_scores = get_test_scores('RF test', rf_preds, y_test)\n",
    "results = pd.concat([results, rf_test_scores], axis=0)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E4JiP5VRz2un"
   },
   "source": [
    "All scores increased by at most ~0.02."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **XGBoost**\n",
    "\n",
    " Try to improve the scores using an XGBoost model.\n",
    "\n",
    "1. Instantiate the XGBoost classifier `xgb` and set `objective='binary:logistic'`. Also set the random state.\n",
    "\n",
    "2. Create a dictionary `cv_params` of the following hyperparameters and their corresponding values to tune:\n",
    " - `max_depth`\n",
    " - `min_child_weight`\n",
    " - `learning_rate`\n",
    " - `n_estimators`\n",
    "\n",
    "3. Define a set `scoring` of scoring metrics for grid search to capture (precision, recall, F1 score, and accuracy).\n",
    "\n",
    "4. Instantiate the `GridSearchCV` object `xgb1`. Pass to it as arguments:\n",
    " - estimator=`xgb`\n",
    " - param_grid=`cv_params`\n",
    " - scoring=`scoring`\n",
    " - cv: define the number of cross-validation folds you want (`cv=_`)\n",
    " - refit: indicate which evaluation metric you want to use to select the model (`refit='f1'`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Instantiate the XGBoost classifier\n",
    "\n",
    "xgb = XGBClassifier(objective='binary:logistic', random_state=0)\n",
    "\n",
    "# 2. Create a dictionary of hyperparameters to tune\n",
    "\n",
    "cv_params = {'learning_rate': [0.1, 0.3],\n",
    "             'max_depth': [8, 10],\n",
    "             'min_child_weight': [2, 5, 10],\n",
    "             'n_estimators': [500]\n",
    "             }\n",
    "\n",
    "# 3. Define a set of scoring metrics to capture\n",
    "scoring = {'accuracy', 'precision', 'recall', 'f1'}\n",
    "\n",
    "# 4. Instantiate the GridSearchCV object\n",
    "xgb1 = GridSearchCV(xgb, cv_params, scoring=scoring, cv=4, refit='f1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now fit the model to the `X_train` and `y_train` data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "xgb1.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the best score from this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine best score\n",
    "xgb1.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2bB-QyGz0RcU"
   },
   "source": [
    "And the best parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "JiLja3YViTzj"
   },
   "outputs": [],
   "source": [
    "# Examine best parameters\n",
    "xgb1.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eTE2QdNP0eEP"
   },
   "source": [
    "##### XGB CV Results\n",
    "\n",
    "Use the `make_results()` function to output all of the scores of your model. Note that it accepts three arguments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "L4TSYXJWiTxs"
   },
   "outputs": [],
   "source": [
    "# Call 'make_results()' on the GridSearch object\n",
    "xgb1_cv_results = make_results('XGB CV', xgb1, 'f1')\n",
    "results = pd.concat([results, xgb1_cv_results], axis=0)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "5Y2giCN32Dwc"
   },
   "outputs": [],
   "source": [
    "# Get scores on test data\n",
    "xgb_preds = xgb1.best_estimator_.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cEwnNMMP2Nbb"
   },
   "source": [
    "###### XGB test results\n",
    "\n",
    "1. Use the `get_test_scores()` function to generate the scores on the test data. Assign the results to `xgb_test_scores`.\n",
    "2. Call `xgb_test_scores` to output the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "g7jShC2TiTvx"
   },
   "outputs": [],
   "source": [
    "# Get scores on test data\n",
    "xgb_test_scores = get_test_scores('XGB test', xgb_preds, y_test)\n",
    "results = pd.concat([results, xgb_test_scores], axis=0)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "saM8YwbAyi-F"
   },
   "source": [
    "The F<sub>1</sub> score is ~0.01 lower than the random forest model. Both models are acceptable, but the random forest model is the champion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eCNH80Ku9TpO"
   },
   "source": [
    "Plot a confusion matrix of the model's predictions on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "5iUyZWjWvqOd"
   },
   "outputs": [],
   "source": [
    "# Generate array of values for confusion matrix\n",
    "cm = confusion_matrix(y_test, rf_preds, labels=rf1.classes_)\n",
    "\n",
    "# Plot confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                             display_labels=rf1.classes_, \n",
    "                             )\n",
    "disp.plot(values_format='');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dW-3_eWW-k2u"
   },
   "source": [
    "The model is almost twice as likely to predict a false positive than it is to predict a false negative. Therefore, type I errors are more common. This is less desirable, because it's better for a driver to be pleasantly surprised by a generous tip when they weren't expecting one than to be disappointed by a low tip when they were expecting a generous one. However, the overall performance of this model is satisfactory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XNexnwvy09PK"
   },
   "source": [
    "##### Feature importance\n",
    "\n",
    "Use the `feature_importances_` attribute of the best estimator object to inspect the features of our final model. We can then sort them and plot the most important ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "kz5T1gHc1R2x"
   },
   "outputs": [],
   "source": [
    "importances = rf1.best_estimator_.feature_importances_\n",
    "rf_importances = pd.Series(importances, index=X_test.columns)\n",
    "rf_importances = rf_importances.sort_values(ascending=False)[:15]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "rf_importances.plot.bar(ax=ax)\n",
    "ax.set_title('Feature importances')\n",
    "ax.set_ylabel('Mean decrease in impurity')\n",
    "fig.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ill21hQ4ej9-"
   },
   "source": [
    "### **Task 4. Conclusion**\n",
    "\n",
    "F1 score of this model was 0.7235 and it had an overall accuracy of 0.6865. It correctly identified ~78% of the actual responders in the test set, which is 48% better than a random guess. It may be worthwhile to test the model with a select group of taxi drivers to get feedback.\n",
    "\n",
    "Unfortunately, random forest is not the most transparent machine learning algorithm. We know that VendorID, predicted_fare, mean_duration, and mean_distance are the most important features, but we don't know how they influence tipping. This would require further exploration."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": [
    {
     "file_id": "1oNheYh5WbljxkvoK_BMkQTey2DWnFXMs",
     "timestamp": 1663785370813
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
